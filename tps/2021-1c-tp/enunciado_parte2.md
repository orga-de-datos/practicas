# Introducci√≥n
Luego de la presentaci√≥n del informe y el baseline FiuFip quiere profundizar su campa√±a de recaudaci√≥n. Gracias al √©xito 
logrado en la primera campa√±a la organizaci√≥n tiene m√°s confianza en ustedes y sus ‚Äúalgoritmos‚Äù y est√° ansiosa por probar 
las avanzadas t√©cnicas de inteligencia artificial de las que todo el mundo habla (y de las que otras organizaciones secretas
chismosean).  


## Tarea
El director general de recaudaci√≥n est√° muy interesado en utilizar algoritmos de machine learning desde que escuch√≥ 
que el otro equipo (esos engreidos de FiuDec) lo utiliza para pronosticar los aumentos de precios, por esto es que hizo un curso 
para entender c√≥mo funciona. Con su conocimiento al respecto exige que probemos varios modelos (al menos 5 tipos distintos) 
reportando cual de todos fue el mejor (seg√∫n la m√©trica AUC-ROC), tambi√©n pretende que utilicemos t√©cnicas para buscar la mejor
configuraci√≥n de hiperpar√°metros, que intentemos hacer al menos un ensamble, que utilicemos cross-validation para comparar los modelos y 
que presentemos varias m√©tricas del modelo final:  
- AUC-ROC
- Matriz de confusi√≥n
- Accuracy
- Precisi√≥n
- Recall

El director tambi√©n sabe los dilemas que resultan de llevar un prototipo a producci√≥n, por lo que nos pidi√≥ 
encarecidamente que dejemos muy expl√≠citos los pasos de pre-procesamiento/feature engineering que usamos en cada 
modelo, y que dejemos toda la l√≥gica del preprocesado en un archivo python llamado preprocesing.py en donde van a 
estar todas las funciones utilizadas para preprocesamiento, de hecho, √©l espera que apliquemos al menos dos tecnicas
de preprocesamiento distintos por cada tipo de modelo y espera que si dos modelos tienen el mismo preprocesado 
entonces usen la misma funci√≥n en preprocessing.py.  

## Entrega
El formato de entrega va a ser un breve informe en PDF con:

**(TABLA 1)** Tabla que liste todos los pre-procesamientos utilizados, con el estilo:  
\<nombre preprocesamiento\> \< explicaci√≥n simple\> \< nombre de la funci√≥n de python \>  
En donde:  
- **nombre preprocesamiento:** es un nombre que ustedes elijan para representar lo que hace el preprocesado.
- **explicaci√≥n simple:** es una descripci√≥n en no m√°s de 2 l√≠neas de la l√≥gica de preprocesado.
- **nombre de la funci√≥n de python:** nombre de la funci√≥n de python que va a estar localizada en preprocessing.py


**(TABLA 2)** Tabla que liste:  
\<Nombre Modelo\> \<nombre preprocesamiento\>  \<AUC-ROC\> \<Accuracy\> \<Precision\> \<Recall\> \<F1 score\>  
En donde :  
- **Nombre Modelo:** es el mejor modelo de los de su mismo tipo, enumerados en orden secuencial que se fueron realizando (\<n√∫mero\> - \<nombre\>).
- **nombre preprocesamiento:** es el nombre del preprocesamiento (tiene que estar presente en la tabla anterior)
- (el resto de las columnas son las m√©tricas de ese Nombre Modelo)

En concordancia con lo anterior, se espera que cada Nombre Modelo este en un notebook separado con el nombre
\<Nombre Modelo\>.ipynb y que dentro del mismo est√© de forma clara la llamada a los preprocesados, su entrenamiento, 
la evaluaci√≥n del mismo y finalmente una predicci√≥n en formato csv de un archivo nuevo localizado
en: https://docs.google.com/spreadsheets/d/1ObsojtXfzvwicsFieGINPx500oGbUoaVTERTc69pzxE  
El director nos pide que por cada modelo listado en la tabla, hagamos las predicciones de este archivo y en la entrega junto con los notebook 
tambi√©n entreguemos todas las predicciones. El nombre del archivo con las predicciones tiene que ser \<Nombre Modelo\>.csv, 
el tiene pensado chequear las m√©tricas de estas predicciones minutos antes de pagarnos ( esperemos que no nos cague  üëÄ ).

**(CONCLUSI√ìN)**
Finalmente luego de poner las tablas TABLA 1 y TABLA 2, nos piden que lleguemos a una conclusi√≥n sobre qu√© modelo 
recomendamos y por qu√© y que lo comparemos con respecto al baseline que anteriormente implementamos. Tambien quiere 
que agreguemos un peque√±o analisis de que modelo elegiriamos si se necesitase tener la menor cantidad de falsos positivos
o si necesitan tener una lista de todos los que potencialmente son de valor adquisitivo sin preocuparse demasiado 
si metemos en la misma personas que realmente no tienen alto valor adquisitivo.


## Notas T√©cnicas:
- El formato esperado para las predicciones realizadas en cada .csv es igual al del archivo de ejemplo https://docs.google.com/spreadsheets/d/1jc4bfOyp80opnBnTBupqXnJajyF3a9NVuS9_c8XR7zU en donde por cada 
l√≠nea del archivo se tiene:  
\<id\> \<tiene_alto_valor_adquisitivo\>  
- Todos los notebooks deben poder ser ejecutados de principio a fin por su corrector produciendo los mismos resultados
- Todas las dependencias de librer√≠as deben estar en un requirements.txt
- La entrega se tiene que realizar en el mismo repositorio de la primera entrega, en una carpeta llamada parte_2
- Las predicciones de cada modelo se deberan guardar en el directorio parte_2/predicciones

## Fecha de entrega:
- Entrega: 13 de Julio
- Defensa oral del tp: 20 de Julio  

Nota: entre la entrega y la defensa oral se pueden llegar a pedir correcciones para antes de la defensa oral de 
considerarse necesarias.
